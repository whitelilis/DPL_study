{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.abspath(\"/Users/liuzhe/github/DPL_study/pys\"))\n",
    "#from single_env_from_csv import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#e = SingleEnv('/Users/liuzhe/github/DPL_study/data/snap.csv', 'rb')\n",
    "one_long = torch.tensor([1, 0, 0, 0])\n",
    "one_short = torch.tensor([0, 1, 0, 0])\n",
    "one_close = torch.tensor([0, 0, 1, 0])\n",
    "one_hold = torch.tensor([0, 0, 0, 1])\n",
    "print(3)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timeline: 31, net: 200810.0, cash: 199990, profile: 820.0, direction: 1, in_price: 6894.0, now_price: 6976.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "            day      time   price\n0      20200203  09:00:00  6895.0\n1      20200203  09:00:01  6894.0\n2      20200203  09:00:02  6886.0\n3      20200203  09:00:03  6894.0\n4      20200203  09:00:04  6888.0\n...         ...       ...     ...\n17064  20200203  15:14:35    -1.0\n17065  20200203  15:14:36    -1.0\n17066  20200203  15:14:37    -1.0\n17067  20200203  15:14:38    -1.0\n17068  20200203  15:14:39    -1.0\n\n[17069 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>day</th>\n      <th>time</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20200203</td>\n      <td>09:00:00</td>\n      <td>6895.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20200203</td>\n      <td>09:00:01</td>\n      <td>6894.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20200203</td>\n      <td>09:00:02</td>\n      <td>6886.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20200203</td>\n      <td>09:00:03</td>\n      <td>6894.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20200203</td>\n      <td>09:00:04</td>\n      <td>6888.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17064</th>\n      <td>20200203</td>\n      <td>15:14:35</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>17065</th>\n      <td>20200203</td>\n      <td>15:14:36</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>17066</th>\n      <td>20200203</td>\n      <td>15:14:37</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>17067</th>\n      <td>20200203</td>\n      <td>15:14:38</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>17068</th>\n      <td>20200203</td>\n      <td>15:14:39</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>17069 rows Ã— 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.render()\n",
    "e.data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[194.5166, 194.1873]]], grad_fn=<SqueezeBackward1>)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "d1 = torch.nn.Linear(100, 50) # y = A(100x50) * x + b,\n",
    "input = torch.rand(140, 100)\n",
    "out = d1(input)\n",
    "out.shape\n",
    "\n",
    "\n",
    "d2 = torch.nn.Linear(4, 5)\n",
    "input_matrix = torch.tensor([[1.0, 0.0, 0.0, 0.0]])\n",
    "F.relu(d2(input_matrix))\n",
    "\n",
    "d3 = torch.nn.Conv1d(4, 1, 3)\n",
    "\n",
    "time_input = torch.tensor([[\n",
    "    [323.0, 324.0, 323.0, 325.0,], # tick\n",
    "    [310.0, 310.0, 310.0, 311.0,], # min\n",
    "    [300.0, 300.0, 300.0, 300.0],  # hour\n",
    "    [300.0, 300.0, 300.0, 300.0],  # hour\n",
    "]])\n",
    "\n",
    "d4 = torch.nn.Conv2d(4, 1, 3)\n",
    "\n",
    "d3(time_input)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 1.0032e+00,  1.5410e+00, -1.4889e+00,  ...,  5.6558e-01,\n           1.1138e+00, -1.4912e-01],\n         [ 1.3747e+00, -7.8695e-01,  3.1138e-01,  ..., -1.2692e+00,\n           2.9460e-01, -5.9962e-01],\n         [ 1.3950e+00, -1.8491e-01, -8.0086e-01,  ..., -1.2672e-01,\n           8.3042e-02,  1.0856e+00],\n         ...,\n         [-1.1643e+00, -1.2447e+00,  1.4328e-01,  ..., -6.3540e-01,\n          -1.4191e-01, -6.9446e-02],\n         [-9.4009e-01, -1.1390e+00,  1.1633e+00,  ...,  2.2204e+00,\n           8.5232e-01, -5.0902e-01],\n         [-1.2908e+00, -1.2359e+00,  1.5395e+00,  ...,  1.7412e-01,\n           1.1299e+00,  9.7528e-01]],\n\n        [[ 2.7921e-01,  3.1281e-01, -3.4398e-01,  ..., -7.2510e-02,\n           3.3203e-01, -7.1003e-01],\n         [ 3.9266e-01,  5.8563e-01, -2.7171e-01,  ..., -1.0725e+00,\n          -1.2559e+00, -4.1624e-01],\n         [-1.1150e+00, -6.9392e-01, -1.8016e+00,  ...,  3.9284e-01,\n          -4.6485e-01,  6.6194e-01],\n         ...,\n         [ 2.1654e-01,  6.0201e-01,  3.3691e-02,  ...,  4.6986e-01,\n           1.4837e-01, -1.3362e+00],\n         [ 7.9448e-01, -6.6644e-01,  7.1162e-01,  ..., -7.9930e-01,\n           1.4405e+00,  7.9251e-01],\n         [-3.3224e-01, -3.4175e-01,  1.3843e+00,  ...,  9.2714e-01,\n           8.4039e-02, -1.2285e+00]],\n\n        [[-9.3567e-03,  8.6027e-02, -4.3412e-01,  ..., -1.4188e+00,\n          -8.0862e-01,  1.5486e+00],\n         [ 2.8920e-01,  4.1086e-01, -3.5472e-01,  ...,  2.1468e+00,\n           2.8666e-01, -3.7711e-02],\n         [ 2.4898e-01,  1.0732e+00,  5.0951e-01,  ...,  5.0572e-01,\n           6.3126e-01,  1.1858e-01],\n         ...,\n         [-3.4524e-01, -8.0831e-01, -1.5516e+00,  ..., -7.9760e-01,\n          -1.2313e+00,  1.7586e-01],\n         [ 5.4109e-01, -1.0377e-01, -9.0206e-01,  ..., -7.4169e-01,\n          -4.4463e-01,  1.6214e+00],\n         [ 1.8239e-01, -3.6530e+00, -6.9980e-01,  ..., -1.3099e+00,\n           4.2064e-01,  2.5729e-01]],\n\n        [[ 1.2071e+00, -1.1735e+00,  1.2472e+00,  ..., -1.6244e+00,\n           8.4351e-01,  6.1060e-01],\n         [-4.0541e-01, -4.9690e-01, -3.7486e-01,  ...,  4.9224e-01,\n           1.4569e+00, -6.1735e-01],\n         [ 1.2673e-01, -2.4354e+00,  8.9739e-01,  ..., -2.3395e-01,\n           5.0042e-01,  9.8337e-01],\n         ...,\n         [-4.5627e-01,  1.7882e-01, -5.7119e-01,  ..., -5.1068e-01,\n           1.9890e+00,  6.0853e-01],\n         [-2.0526e-01, -3.4453e-01, -1.0769e+00,  ...,  1.4071e-02,\n          -1.5218e+00, -1.0328e+00],\n         [-9.1127e-01,  5.0668e-01,  1.2606e-02,  ..., -1.7348e-01,\n          -5.4028e-02,  4.6613e-02]],\n\n        [[-8.6722e-02, -6.0337e-01,  2.8575e-01,  ...,  8.4276e-02,\n           3.8614e-01,  7.2180e-01],\n         [ 7.2902e-01, -5.7837e-01, -1.8569e+00,  ...,  2.1034e+00,\n           1.4070e-03,  1.1796e+00],\n         [ 1.2621e+00, -6.7936e-01, -6.4928e-01,  ...,  6.9159e-01,\n           3.4284e-01,  1.9620e-01],\n         ...,\n         [-7.9765e-01, -9.8332e-01, -3.8737e-03,  ..., -8.4813e-01,\n           7.8682e-03, -6.9571e-01],\n         [-4.0686e-01, -8.5153e-01,  2.1620e-02,  ...,  8.7560e-01,\n           3.3773e-01,  4.4299e-01],\n         [-4.0438e-01, -1.0703e+00, -3.0998e-01,  ...,  1.2816e+00,\n           7.3518e-01, -2.4324e-02]],\n\n        [[-9.2360e-01, -1.0558e-01,  1.3222e+00,  ...,  1.9471e-01,\n           9.9296e-01,  5.5728e-01],\n         [ 1.4092e+00,  7.9511e-01,  1.3212e+00,  ..., -9.6046e-02,\n           1.1244e+00, -1.1593e+00],\n         [-1.2178e+00, -4.0214e-01, -6.5836e-01,  ..., -2.7516e-01,\n          -5.3313e-01,  1.4634e+00],\n         ...,\n         [ 7.8348e-01,  1.0556e+00,  3.7951e-01,  ..., -7.0250e-03,\n           3.2192e-01, -6.4304e-01],\n         [-3.3829e-02,  1.3952e+00, -1.7055e+00,  ..., -9.6293e-01,\n           8.4454e-01, -1.7148e+00],\n         [ 1.1025e+00, -7.3107e-01, -9.9790e-01,  ..., -1.2401e-01,\n          -1.3021e+00,  3.4774e-01]]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_num = 15\n",
    "step_num = 20\n",
    "time_scales = len(['tick', 'min', '5min', '15min', 'hour', 'day'])\n",
    "action_count = len(['b1', 's1', 'h', 'c'])\n",
    "\n",
    "fake_tick = torch.randn((time_scales, step_num, metric_num)) #\n",
    "fake_tick\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6, 10, 2])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_out_rows = 10\n",
    "\n",
    "mod = torch.nn.Sequential(\n",
    "    torch.nn.Conv1d(step_num, conv_out_rows, 4),\n",
    "    torch.nn.Flatten(end_dim=1)\n",
    ")\n",
    "out = mod(fake_tick)\n",
    "out.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([432])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.reshape(-1).size()\n",
    "\n",
    "fake_tick.size()\n",
    "t1 = torch.nn.Conv2d(time_scales, 9, (5, 3))\n",
    "t1(fake_tick.unsqueeze(0)).view(-1).size()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/br0t0rj942x005pnp5ghxfy40000gn/T/ipykernel_37709/4049721819.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return lin_out, torch.nn.functional.softmax(lin_out)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([ 0.0386, -0.0391,  0.0088, -0.0126], grad_fn=<AddBackward0>),\n tensor([0.2600, 0.2406, 0.2524, 0.2470], grad_fn=<SoftmaxBackward>))"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_h = 6 # segment_range\n",
    "kernel_w = 3 # metric_kinds\n",
    "\n",
    "cons = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(time_scales, time_scales, (kernel_h, kernel_w), padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(time_scales, time_scales, (kernel_h, kernel_w), padding=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(time_scales, time_scales, (kernel_h, kernel_w), padding=1),\n",
    "    torch.nn.ReLU()\n",
    ")\n",
    "\n",
    "cons(fake_tick.unsqueeze(0)).size()\n",
    "#fake_tick.unsqueeze(0).size()\n",
    "in_w = len(cons(fake_tick.unsqueeze(0)).view(-1))\n",
    "\n",
    "lins = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_w, in_w),\n",
    "    torch.nn.Linear(in_w, in_w),\n",
    "    torch.nn.Linear(in_w, action_count),\n",
    ")\n",
    "\n",
    "def forward(x):\n",
    "    con_out = cons(x.unsqueeze(0))\n",
    "    lin_out = lins(con_out.view(-1))\n",
    "    return lin_out, torch.nn.functional.softmax(lin_out)\n",
    "\n",
    "forward(fake_tick)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(3)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.tensor([0.1, 0.4, 0.3, 0.5])\n",
    "torch.argmax(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([6, 20, 15])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1 = torch.tensor([[[7.0, 22.0, 14.0, 29.0, 49.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 786.0, 430.0, 3471.0, 3994.0, 960782.0], [7.0, 22.0, 14.0, 29.0, 50.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 786.0, 433.0, 3471.0, 3994.0, 960782.0], [7.0, 22.0, 14.0, 29.0, 50.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 789.0, 430.0, 3471.0, 3994.0, 960786.0], [7.0, 22.0, 14.0, 29.0, 51.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 790.0, 428.0, 3471.0, 3994.0, 960788.0], [7.0, 22.0, 14.0, 29.0, 51.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 811.0, 86.0, 3471.0, 3994.0, 960788.0], [7.0, 22.0, 14.0, 29.0, 52.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 812.0, 63.0, 3471.0, 3994.0, 960788.0], [7.0, 22.0, 14.0, 29.0, 52.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 802.0, 65.0, 3471.0, 3994.0, 960798.0], [7.0, 22.0, 14.0, 29.0, 53.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 803.0, 66.0, 3471.0, 3994.0, 960798.0], [7.0, 22.0, 14.0, 29.0, 53.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 813.0, 66.0, 3471.0, 3994.0, 960799.0], [7.0, 22.0, 14.0, 29.0, 54.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 817.0, 417.0, 3471.0, 3994.0, 960814.0], [7.0, 22.0, 14.0, 29.0, 54.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 795.0, 441.0, 3471.0, 3994.0, 960817.0], [7.0, 22.0, 14.0, 29.0, 55.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 795.0, 425.0, 3471.0, 3994.0, 960817.0], [7.0, 22.0, 14.0, 29.0, 55.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 799.0, 565.0, 3471.0, 3994.0, 960817.0], [7.0, 22.0, 14.0, 29.0, 56.0, 3.0, 3790.000000000001, 3790.000000000001, 3790.000000000001, 3790.000000000001, 795.0, 567.0, 3471.0, 3994.0, 960821.0], [7.0, 22.0, 14.0, 29.0, 56.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 795.0, 568.0, 3471.0, 3994.0, 960822.0], [7.0, 22.0, 14.0, 29.0, 57.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 795.0, 568.0, 3471.0, 3994.0, 960822.0], [7.0, 22.0, 14.0, 29.0, 58.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 795.0, 568.0, 3471.0, 3994.0, 960822.0], [7.0, 22.0, 14.0, 29.0, 58.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 815.0, 575.0, 3471.0, 3994.0, 960822.0], [7.0, 22.0, 14.0, 29.0, 59.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 809.0, 594.0, 3471.0, 3994.0, 960829.0], [7.0, 22.0, 14.0, 29.0, 59.0, 3.0, 3791.0, 3791.0, 3791.0, 3791.0, 810.0, 594.0, 3471.0, 3994.0, 960829.0]], [[7.0, 22.0, 14.0, 10.0, 59.0, 3.0, 3794.0, 3795.000000000001, 3793.0, 3794.000000000001, 369.0, 170.0, 3471.0, 3994.0, 923444.0], [7.0, 22.0, 14.0, 11.0, 59.0, 3.0, 3794.000000000001, 3795.0, 3794.0, 3795.0, 261.0, 165.0, 3471.0, 3994.0, 924477.0], [7.0, 22.0, 14.0, 12.0, 59.0, 3.0, 3795.0, 3796.0, 3794.0, 3795.0, 90.0, 1072.0, 3471.0, 3994.0, 924883.0], [7.0, 22.0, 14.0, 13.0, 59.0, 3.0, 3796.0, 3797.000000000001, 3794.0, 3796.0, 402.0, 977.0, 3471.0, 3994.0, 926348.0], [7.0, 22.0, 14.0, 14.0, 59.0, 3.0, 3796.0, 3797.0, 3795.0, 3797.0, 55.0, 837.0, 3471.0, 3994.0, 927739.0], [7.0, 22.0, 14.0, 15.0, 59.0, 3.0, 3797.0, 3797.000000000001, 3795.0, 3797.0, 288.0, 826.0, 3471.0, 3994.0, 928454.0], [7.0, 22.0, 14.0, 16.0, 59.0, 3.0, 3796.000000000001, 3797.0, 3796.0, 3797.0, 177.0, 652.0, 3471.0, 3994.0, 929037.0], [7.0, 22.0, 14.0, 17.0, 59.0, 3.0, 3797.0, 3798.0, 3796.0, 3798.0, 5.0, 1030.0, 3471.0, 3994.0, 930132.0], [7.0, 22.0, 14.0, 18.0, 59.0, 3.0, 3797.0, 3798.0, 3796.0, 3798.0, 403.0, 359.0, 3471.0, 3994.0, 931980.0], [7.0, 22.0, 14.0, 19.0, 59.0, 3.0, 3798.0, 3799.000000000001, 3797.0, 3799.0, 468.0, 582.0, 3471.0, 3994.0, 933383.0], [7.0, 22.0, 14.0, 20.0, 59.0, 3.0, 3799.0, 3799.000000000001, 3797.0, 3799.0, 81.0, 413.0, 3471.0, 3994.0, 935689.0], [7.0, 22.0, 14.0, 21.0, 59.0, 3.0, 3799.0, 3800.0, 3797.0, 3798.0, 325.0, 26.0, 3471.0, 3994.0, 937973.0], [7.0, 22.0, 14.0, 22.0, 59.0, 3.0, 3798.0, 3799.0, 3797.0, 3797.0, 314.0, 418.0, 3471.0, 3994.0, 938826.0], [7.0, 22.0, 14.0, 23.0, 59.0, 3.0, 3797.0, 3798.0, 3794.0, 3794.0, 488.0, 11.0, 3471.0, 3994.0, 940542.0], [7.0, 22.0, 14.0, 24.0, 59.0, 3.0, 3794.0, 3794.000000000001, 3792.0, 3794.000000000001, 203.0, 609.0, 3471.0, 3994.0, 942662.0], [7.0, 22.0, 14.0, 25.0, 59.0, 3.0, 3794.000000000001, 3794.000000000001, 3788.0, 3790.0, 278.0, 125.0, 3471.0, 3994.0, 949933.0], [7.0, 22.0, 14.0, 26.0, 59.0, 3.0, 3790.0, 3791.0, 3789.0, 3790.0, 243.0, 575.0, 3471.0, 3994.0, 952140.0], [7.0, 22.0, 14.0, 27.0, 59.0, 3.0, 3790.0, 3790.0, 3787.0, 3788.0, 101.0, 296.0, 3471.0, 3994.0, 955588.0], [7.0, 22.0, 14.0, 28.0, 59.0, 3.0, 3788.0, 3791.0, 3788.0, 3790.0, 594.0, 375.0, 3471.0, 3994.0, 958904.0], [7.0, 22.0, 14.0, 29.0, 59.0, 3.0, 3790.0, 3792.000000000001, 3790.0, 3791.0, 810.0, 594.0, 3471.0, 3994.0, 960829.0]], [[7.0, 22.0, 10.0, 54.0, 59.0, 3.0, 3783.0, 3791.000000000001, 3782.0, 3790.0, 230.0, 381.0, 3471.0, 3994.0, 798760.0], [7.0, 22.0, 10.0, 59.0, 59.0, 3.0, 3790.0, 3793.0, 3788.0, 3791.0, 58.0, 379.0, 3471.0, 3994.0, 808204.0], [7.0, 22.0, 11.0, 4.0, 59.0, 3.0, 3791.0, 3792.0, 3788.0, 3792.0, 207.0, 593.0, 3471.0, 3994.0, 814095.0], [7.0, 22.0, 11.0, 9.0, 59.0, 3.0, 3792.0, 3794.0, 3791.0, 3792.0, 381.0, 335.0, 3471.0, 3994.0, 819017.0], [7.0, 22.0, 11.0, 14.0, 59.0, 3.0, 3791.0, 3802.0, 3791.0, 3796.0, 491.0, 197.0, 3471.0, 3994.0, 839485.0], [7.0, 22.0, 11.0, 19.0, 59.0, 3.0, 3796.0, 3799.0, 3793.0, 3797.0, 228.0, 213.0, 3471.0, 3994.0, 845922.0], [7.0, 22.0, 11.0, 24.0, 59.0, 3.0, 3797.0, 3802.0, 3797.0, 3801.0, 386.0, 39.0, 3471.0, 3994.0, 853868.0], [7.0, 22.0, 11.0, 29.0, 59.0, 3.0, 3801.0, 3801.000000000001, 3795.0, 3798.0, 13.0, 21.0, 3471.0, 3994.0, 859603.0], [7.0, 22.0, 13.0, 34.0, 59.0, 3.0, 3793.0, 3795.000000000001, 3787.0, 3793.0, 199.0, 215.0, 3471.0, 3994.0, 876786.0], [7.0, 22.0, 13.0, 39.0, 59.0, 3.0, 3793.0, 3799.0, 3792.0, 3796.0, 429.0, 16.0, 3471.0, 3994.0, 884447.0], [7.0, 22.0, 13.0, 44.0, 59.0, 3.0, 3795.0, 3800.0, 3789.0, 3792.0, 394.0, 273.0, 3471.0, 3994.0, 898271.0], [7.0, 22.0, 13.0, 49.0, 59.0, 3.0, 3792.0, 3795.000000000001, 3791.0, 3794.0, 302.0, 229.0, 3471.0, 3994.0, 901828.0], [7.0, 22.0, 13.0, 54.0, 59.0, 3.0, 3793.0, 3795.000000000001, 3790.0, 3791.0, 86.0, 210.0, 3471.0, 3994.0, 908915.0], [7.0, 22.0, 13.0, 59.0, 59.0, 3.0, 3791.0, 3795.000000000001, 3791.0, 3793.0, 189.0, 242.0, 3471.0, 3994.0, 912888.0], [7.0, 22.0, 14.0, 4.0, 59.0, 3.0, 3794.0, 3796.000000000001, 3792.0, 3794.0, 496.0, 133.0, 3471.0, 3994.0, 917873.0], [7.0, 22.0, 14.0, 9.0, 59.0, 3.0, 3794.0, 3796.0, 3792.0, 3794.0, 875.0, 335.0, 3471.0, 3994.0, 922538.0], [7.0, 22.0, 14.0, 14.0, 59.0, 3.0, 3794.0, 3797.000000000001, 3793.0, 3797.0, 55.0, 837.0, 3471.0, 3994.0, 927739.0], [7.0, 22.0, 14.0, 19.0, 59.0, 3.0, 3797.0, 3799.000000000001, 3795.0, 3799.0, 468.0, 582.0, 3471.0, 3994.0, 933383.0], [7.0, 22.0, 14.0, 24.0, 59.0, 3.0, 3799.0, 3800.0, 3792.0, 3794.000000000001, 203.0, 609.0, 3471.0, 3994.0, 942662.0], [7.0, 22.0, 14.0, 29.0, 59.0, 3.0, 3794.000000000001, 3794.000000000001, 3787.0, 3791.0, 810.0, 594.0, 3471.0, 3994.0, 960829.0]], [[7.0, 22.0, 21.0, 29.0, 59.0, 3.0, 3790.0, 3792.000000000001, 3784.0, 3789.0, 491.0, 18.0, 3471.0, 3994.0, 239962.0], [7.0, 22.0, 21.0, 44.0, 59.0, 3.0, 3789.0, 3791.0, 3773.0, 3778.000000000001, 177.0, 398.0, 3471.0, 3994.0, 293251.0], [7.0, 22.0, 21.0, 59.0, 59.0, 3.0, 3778.000000000001, 3792.0, 3777.0, 3790.0, 392.0, 552.0, 3471.0, 3994.0, 344569.0], [7.0, 22.0, 22.0, 14.0, 59.0, 3.0, 3789.0, 3792.000000000001, 3787.0, 3791.0, 437.0, 414.0, 3471.0, 3994.0, 367645.0], [7.0, 22.0, 22.0, 29.0, 59.0, 3.0, 3791.0, 3795.000000000001, 3785.0, 3786.0, 307.0, 284.0, 3471.0, 3994.0, 400256.0], [7.0, 22.0, 22.0, 44.0, 59.0, 3.0, 3786.0, 3792.000000000001, 3786.0, 3790.0, 44.0, 884.0, 3471.0, 3994.0, 418239.0], [7.0, 22.0, 22.0, 59.0, 59.0, 3.0, 3790.0, 3794.0, 3787.0, 3790.0, 11.0, 15.0, 3471.0, 3994.0, 442464.0], [7.0, 22.0, 9.0, 14.0, 59.0, 3.0, 3794.0, 3816.0, 3790.0, 3806.0, 506.0, 65.0, 3471.0, 3994.0, 561347.0], [7.0, 22.0, 9.0, 29.0, 59.0, 3.0, 3807.0, 3808.0, 3792.0, 3801.0, 460.0, 360.0, 3471.0, 3994.0, 622785.0], [7.0, 22.0, 9.0, 44.0, 59.0, 3.0, 3801.0, 3803.000000000001, 3794.0, 3801.0, 27.0, 319.0, 3471.0, 3994.0, 661898.0], [7.0, 22.0, 9.0, 59.0, 59.0, 3.0, 3800.0, 3802.000000000001, 3794.0, 3797.0, 24.0, 358.0, 3471.0, 3994.0, 682452.0], [7.0, 22.0, 10.0, 14.0, 59.0, 3.0, 3797.0, 3800.000000000001, 3794.0, 3795.0, 125.0, 320.0, 3471.0, 3994.0, 703059.0], [7.0, 22.0, 10.0, 44.0, 59.0, 3.0, 3796.0, 3797.000000000001, 3782.0, 3787.0, 177.0, 321.0, 3471.0, 3994.0, 775762.0], [7.0, 22.0, 10.0, 59.0, 59.0, 3.0, 3787.0, 3793.0, 3782.0, 3791.0, 58.0, 379.0, 3471.0, 3994.0, 808204.0], [7.0, 22.0, 11.0, 14.0, 59.0, 3.0, 3791.0, 3802.0, 3788.0, 3796.0, 491.0, 197.0, 3471.0, 3994.0, 839485.0], [7.0, 22.0, 11.0, 29.0, 59.0, 3.0, 3796.0, 3802.0, 3793.0, 3798.0, 13.0, 21.0, 3471.0, 3994.0, 859603.0], [7.0, 22.0, 13.0, 44.0, 59.0, 3.0, 3793.0, 3800.0, 3787.0, 3792.0, 394.0, 273.0, 3471.0, 3994.0, 898271.0], [7.0, 22.0, 13.0, 59.0, 59.0, 3.0, 3792.0, 3795.000000000001, 3790.0, 3793.0, 189.0, 242.0, 3471.0, 3994.0, 912888.0], [7.0, 22.0, 14.0, 14.0, 59.0, 3.0, 3794.0, 3797.000000000001, 3792.0, 3797.0, 55.0, 837.0, 3471.0, 3994.0, 927739.0], [7.0, 22.0, 14.0, 29.0, 59.0, 3.0, 3797.0, 3800.0, 3787.0, 3791.0, 810.0, 594.0, 3471.0, 3994.0, 960829.0]], [[7.0, 20.0, 22.0, 59.0, 59.0, 1.0, 3744.0, 3749.0, 3723.0, 3734.0, 37.0, 171.0, 3451.0, 3970.0, 391180.0], [7.0, 20.0, 9.0, 59.0, 59.0, 1.0, 3735.0, 3735.0, 3708.0, 3709.0, 550.0, 595.0, 3451.0, 3970.0, 593648.0], [7.0, 20.0, 10.0, 59.0, 59.0, 1.0, 3708.000000000001, 3718.0000000000005, 3701.0, 3716.0, 205.0, 812.0, 3451.0, 3970.0, 713200.0], [7.0, 20.0, 11.0, 29.0, 59.0, 1.0, 3716.0, 3717.000000000001, 3701.0, 3701.0, 758.0, 177.0, 3451.0, 3970.0, 790258.0], [7.0, 20.0, 13.0, 59.0, 59.0, 1.0, 3701.0000000000005, 3711.0, 3696.000000000001, 3701.0, 7.0, 501.0, 3451.0, 3970.0, 893068.0], [7.0, 20.0, 14.0, 59.0, 59.0, 1.0, 3700.0, 3712.0, 3698.0, 3702.000000000001, 75.0, 40.0, 3451.0, 3970.0, 1026156.0], [7.0, 21.0, 21.0, 59.0, 59.0, 2.0, 3699.0, 3712.0, 3697.0, 3705.0, 102.0, 634.0, 3458.0, 3979.0, 142261.0], [7.0, 21.0, 22.0, 59.0, 59.0, 2.0, 3705.0, 3720.000000000001, 3705.0, 3716.0, 919.0, 198.0, 3458.0, 3979.0, 271396.0], [7.0, 21.0, 9.0, 59.0, 59.0, 2.0, 3716.0, 3745.000000000001, 3716.0, 3738.0, 304.0, 161.0, 3458.0, 3979.0, 579003.0], [7.0, 21.0, 10.0, 59.0, 59.0, 2.0, 3738.0, 3741.000000000001, 3728.0, 3733.0, 257.0, 71.0, 3458.0, 3979.0, 658066.0], [7.0, 21.0, 11.0, 29.0, 59.0, 2.0, 3733.0, 3739.000000000001, 3731.0, 3735.0, 136.0, 329.0, 3458.0, 3979.0, 692400.0], [7.0, 21.0, 13.0, 59.0, 59.0, 2.0, 3733.0, 3743.000000000001, 3731.0, 3741.0, 318.0, 753.0, 3458.0, 3979.0, 740114.0], [7.0, 21.0, 14.0, 59.0, 59.0, 2.0, 3742.0, 3765.000000000001, 3739.0, 3764.000000000001, 323.0, 390.0, 3458.0, 3979.0, 1025122.0], [7.0, 22.0, 21.0, 59.0, 59.0, 3.0, 3768.0, 3795.0, 3768.0, 3790.0, 392.0, 552.0, 3471.0, 3994.0, 344569.0], [7.0, 22.0, 22.0, 59.0, 59.0, 3.0, 3789.0, 3795.000000000001, 3785.0, 3790.0, 11.0, 15.0, 3471.0, 3994.0, 442464.0], [7.0, 22.0, 9.0, 59.0, 59.0, 3.0, 3794.0, 3816.0, 3790.0, 3797.0, 24.0, 358.0, 3471.0, 3994.0, 682452.0], [7.0, 22.0, 10.0, 59.0, 59.0, 3.0, 3797.0, 3800.000000000001, 3782.0, 3791.0, 58.0, 379.0, 3471.0, 3994.0, 808204.0], [7.0, 22.0, 11.0, 29.0, 59.0, 3.0, 3791.0, 3802.0, 3788.0, 3798.0, 13.0, 21.0, 3471.0, 3994.0, 859603.0], [7.0, 22.0, 13.0, 59.0, 59.0, 3.0, 3793.0, 3800.0, 3787.0, 3793.0, 189.0, 242.0, 3471.0, 3994.0, 912888.0], [7.0, 22.0, 14.0, 29.0, 59.0, 3.0, 3794.0, 3800.0, 3787.0, 3791.0, 810.0, 594.0, 3471.0, 3994.0, 960829.0]], [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.0, 1.0, 14.0, 59.0, 59.0, 3.0, 3566.0000000000005, 3574.0000000000005, 3542.0, 3567.0, 27.0, 685.0, 3318.0, 3817.0, 1086112.0], [7.0, 2.0, 14.0, 59.0, 59.0, 4.0, 3566.0000000000005, 3581.0000000000005, 3560.0, 3574.0, 46.0, 403.0, 3311.0, 3810.0, 809867.0], [7.0, 3.0, 14.0, 59.0, 59.0, 5.0, 3577.0, 3620.0000000000005, 3574.0, 3619.0, 618.0, 63.0, 3319.0, 3818.0, 1233967.0], [7.0, 6.0, 14.0, 59.0, 59.0, 1.0, 3622.0, 3629.0000000000005, 3603.0, 3618.0, 27.0, 38.0, 3350.0, 3855.0, 949955.0], [7.0, 7.0, 14.0, 59.0, 59.0, 2.0, 3619.0, 3654.0, 3619.0, 3634.0, 32.0, 311.0, 3361.0, 3868.0, 957200.0], [7.0, 8.0, 14.0, 59.0, 59.0, 3.0, 3638.0, 3705.000000000001, 3636.0, 3700.0, 265.0, 7.0, 3381.0, 3890.0, 1368038.0], [7.0, 9.0, 14.0, 59.0, 59.0, 4.0, 3708.0, 3742.000000000001, 3703.0, 3725.0, 40.0, 8.0, 3420.0, 3935.0, 1172490.0], [7.0, 10.0, 14.0, 59.0, 59.0, 5.0, 3723.0, 3723.0, 3680.0, 3690.0, 412.0, 7.0, 3459.0, 3980.0, 1178729.0], [7.0, 13.0, 14.0, 59.0, 59.0, 1.0, 3692.0, 3768.0, 3692.0, 3739.0, 76.0, 364.0, 3443.0, 3962.0, 1377089.0], [7.0, 14.0, 14.0, 59.0, 59.0, 2.0, 3741.0, 3754.000000000001, 3716.0, 3744.0, 67.0, 59.0, 3473.0, 3996.0, 953880.0], [7.0, 15.0, 14.0, 59.0, 59.0, 3.0, 3743.0, 3762.0, 3721.0, 3746.0, 7.0, 5.0, 3473.0, 3996.0, 858731.0], [7.0, 16.0, 14.0, 59.0, 59.0, 4.0, 3739.0, 3743.000000000001, 3692.0, 3702.0, 28.0, 192.0, 3477.0, 4000.0, 1255797.0], [7.0, 17.0, 14.0, 59.0, 59.0, 5.0, 3706.0, 3734.000000000001, 3686.0, 3726.0, 1859.0, 24.0, 3458.0, 3979.0, 926244.0], [7.0, 20.0, 14.0, 59.0, 59.0, 1.0, 3721.0, 3749.0, 3696.000000000001, 3702.000000000001, 75.0, 40.0, 3451.0, 3970.0, 1026156.0], [7.0, 21.0, 14.0, 59.0, 59.0, 2.0, 3699.0, 3765.000000000001, 3697.0, 3764.000000000001, 323.0, 390.0, 3458.0, 3979.0, 1025122.0], [7.0, 22.0, 14.0, 29.0, 59.0, 3.0, 3768.0, 3816.0, 3768.0, 3791.0, 810.0, 594.0, 3471.0, 3994.0, 960829.0]]])\n",
    "r1.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/br0t0rj942x005pnp5ghxfy40000gn/T/ipykernel_37709/4049721819.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return lin_out, torch.nn.functional.softmax(lin_out)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([-2011.3035,  -725.1359, -4176.2686,  1715.6284],\n        grad_fn=<AddBackward0>),\n tensor([0., 0., 0., 1.], grad_fn=<SoftmaxBackward>))"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(r1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/br0t0rj942x005pnp5ghxfy40000gn/T/ipykernel_37709/3688773127.py:24: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return lin_out, torch.nn.functional.softmax(lin_out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class TestNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TestNN, self).__init__()\n",
    "        self.cons = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(time_scales, time_scales, (kernel_h, kernel_w), padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(time_scales, time_scales, (kernel_h, kernel_w), padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(time_scales, time_scales, (kernel_h, kernel_w), padding=1),\n",
    "            torch.nn.ReLU())\n",
    "        #cons(fake_tick.unsqueeze(0)).size()\n",
    "        #fake_tick.unsqueeze(0).size()\n",
    "        in_w = len(cons(fake_tick.unsqueeze(0)).view(-1))\n",
    "        self.lins = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_w, in_w),\n",
    "            torch.nn.Linear(in_w, in_w),\n",
    "            torch.nn.Linear(in_w, action_count))\n",
    "    def forward(self, x):\n",
    "        con_out = self.cons(x.unsqueeze(0))\n",
    "        lin_out = self.lins(con_out.view(-1))\n",
    "        return lin_out, torch.nn.functional.softmax(lin_out)\n",
    "\n",
    "tt = TestNN()\n",
    "torch.onnx.export(tt, r1, \"test.onnx\", opset_version=11)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python396jvsc74a57bd0b083a35c829d90d7cf4bf5a162f9b5913befed75f21b4e95e09572b3db361c53",
   "language": "python",
   "display_name": "Python 3.9.6 64-bit ('torch_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}